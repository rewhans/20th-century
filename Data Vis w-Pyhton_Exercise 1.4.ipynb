{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeff9cae-dacc-4c65-9d37-2aeb0faca98a",
   "metadata": {},
   "source": [
    "# Achievement 1.4: Web Scraping Project\n",
    "\n",
    "This notebook scrapes data from two Wikipedia pages and saves the results to text files. The process involves using Selenium to automate a browser and BeautifulSoup to parse the page content.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Imports and Setup](#1.-Imports-and-Setup)\n",
    "2. [Helper Functions](#2.-Helper-Functions)\n",
    "3. [Scraping Logic](#3.-Scraping-Logic)\n",
    "4. [Main Execution](#4.-Main-Execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f3c0a-27d3-4701-91df-7251e51a274f",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "This first code block imports all the necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da79abc7-1549-4861-b446-dafffd0a1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522e1f6-4a36-4908-80c2-43410fb35d1d",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "This section contains the utility functions for setting up the Selenium WebDriver and for saving the scraped data to local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b9125cc-4e12-40bb-948a-3907935a8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver(driver_path):\n",
    "    \"\"\"\n",
    "    Initializes and returns a Selenium WebDriver instance.\n",
    "\n",
    "    Args:\n",
    "        driver_path (str): The absolute file path to the chromedriver executable.\n",
    "\n",
    "    Returns:\n",
    "        A Selenium WebDriver object.\n",
    "    \"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # The script can be run headlessly by uncommenting the following line.\n",
    "    # options.add_argument(\"--headless\")\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def save_timeline_file(events, filename=\"20th_century_events.txt\"):\n",
    "    \"\"\"\n",
    "    Saves the timeline events to a text file with Markdown formatting.\n",
    "\n",
    "    Args:\n",
    "        events (list): A list of (decade, event) tuples.\n",
    "        filename (str): The name of the file to save.\n",
    "    \"\"\"\n",
    "    if not events:\n",
    "        return\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# Key Events of the 20th Century\\n\")\n",
    "        last_decade_written = \"\"\n",
    "        for decade, event in events:\n",
    "            # Add a new Markdown header when the decade changes.\n",
    "            if decade != last_decade_written:\n",
    "                f.write(f\"\\n## {decade}\\n\\n\")\n",
    "                last_decade_written = decade\n",
    "            # Write each event as a Markdown bullet point.\n",
    "            f.write(f\"- {event}\\n\")\n",
    "\n",
    "def save_countries_file(countries, filename=\"country_list.txt\"):\n",
    "    \"\"\"\n",
    "    Saves the list of countries to a simple text file.\n",
    "\n",
    "    Args:\n",
    "        countries (list): A list of country names.\n",
    "        filename (str): The name of the file to save.\n",
    "    \"\"\"\n",
    "    if not countries:\n",
    "        return\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for country in countries:\n",
    "            f.write(f\"{country}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc3673-ded6-408c-b17f-dd8df330f408",
   "metadata": {},
   "source": [
    "## 3. Scraping Logic\n",
    "The functions below contain the core logic for scraping each of the two target webpages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f46df50-84ec-44ae-9946-6fa6785dfac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_timeline_events(driver):\n",
    "    \"\"\"\n",
    "    Navigates to the 20th-century timeline page and scrapes event data.\n",
    "\n",
    "    Args:\n",
    "        driver: An active Selenium WebDriver instance.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples, where each tuple contains a decade and an event description.\n",
    "    \"\"\"\n",
    "    # Navigate to the target URL and allow time for dynamic content to load.\n",
    "    url = \"https://en.wikipedia.org/wiki/Timeline_of_the_20th_century\"\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Parse the page's HTML to find the main content container.\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    content_div = soup.find(\"div\", class_=\"mw-parser-output\")\n",
    "    \n",
    "    events = []\n",
    "    if not content_div:\n",
    "        return events\n",
    "\n",
    "    # Isolate section headers (H2 tags) that have a decade-formatted ID.\n",
    "    all_h2s = content_div.find_all(\"h2\", id=True)\n",
    "    decade_headers = []\n",
    "    for h2 in all_h2s:\n",
    "        # A valid decade ID is numeric and ends with 's' (e.g., \"1900s\").\n",
    "        if h2['id'].endswith('s') and h2['id'][:-1].isdigit():\n",
    "            decade_headers.append(h2)\n",
    "\n",
    "    # Process each decade section to extract associated events.\n",
    "    for header in decade_headers:\n",
    "        current_decade = header['id']\n",
    "        \n",
    "        # Start searching from the header's parent div to find sibling elements.\n",
    "        parent_div = header.find_parent('div', class_='mw-heading')\n",
    "\n",
    "        for sibling in parent_div.find_next_siblings():\n",
    "            # Stop processing when the next decade's header is reached.\n",
    "            if sibling.name == 'div' and sibling.find('h2'):\n",
    "                break\n",
    "            \n",
    "            # Extract text from all list items within any unordered list (ul).\n",
    "            if sibling.name == 'ul':\n",
    "                for li in sibling.find_all('li'):\n",
    "                    event_text = li.get_text(strip=True)\n",
    "                    if event_text:\n",
    "                        events.append((current_decade, event_text))\n",
    "    return events\n",
    "\n",
    "def scrape_country_list(driver):\n",
    "    \"\"\"\n",
    "    Navigates to the list of countries page and scrapes the country names.\n",
    "\n",
    "    Args:\n",
    "        driver: An active Selenium WebDriver instance.\n",
    "\n",
    "    Returns:\n",
    "        A sorted list of unique country names.\n",
    "    \"\"\"\n",
    "    # Navigate to the target URL for the bonus task.\n",
    "    country_url = \"https://en.wikipedia.org/wiki/List_of_countries_by_continent\"\n",
    "    driver.get(country_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Parse the new page's HTML.\n",
    "    country_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    country_content_div = country_soup.find(\"div\", class_=\"mw-parser-output\")\n",
    "    \n",
    "    countries = []\n",
    "    if not country_content_div:\n",
    "        return countries\n",
    "\n",
    "    # Find all list items, as countries are contained within them.\n",
    "    list_items = country_content_div.find_all('li')\n",
    "    \n",
    "    for item in list_items:\n",
    "        # A valid country link has a 'title' attribute and is not a link to a file.\n",
    "        link = item.find('a')\n",
    "        if link and link.has_attr('title') and not link['href'].startswith('/wiki/File:'):\n",
    "            country_name = link.get_text(strip=True)\n",
    "            # This check helps exclude non-country list items (e.g., single letters).\n",
    "            if ' ' in country_name or len(country_name) > 3:\n",
    "                 countries.append(country_name)\n",
    "\n",
    "    # Return a sorted list of unique country names.\n",
    "    return sorted(list(set(countries)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36cb50f-0ebb-44dd-a5c6-e3b814e4b90d",
   "metadata": {},
   "source": [
    "## 4. Main Execution\n",
    "This final block of code runs the main logic of the script by calling the functions defined in the cells above. It sets up the driver, executes the scraping tasks, saves the files, and prints a final summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6845d5-e38b-4b3b-b341-17b546968582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Scraping Complete ---\n",
      "Saved 1176 events to 20th_century_events.txt\n",
      "Saved 189 countries to country_list.txt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute the scraping tasks.\n",
    "    \"\"\"\n",
    "    chromedriver_path = r'C:\\Users\\rewha\\Ryan_Wick_Data Vis w-Python_Ach-01.00_CODE\\chromedriver-win64\\chromedriver.exe'\n",
    "    \n",
    "    driver = setup_driver(chromedriver_path)\n",
    "\n",
    "    # --- Execute Main Task ---\n",
    "    timeline_events = scrape_timeline_events(driver)\n",
    "    save_timeline_file(timeline_events)\n",
    "\n",
    "    # --- Execute Bonus Task ---\n",
    "    country_list = scrape_country_list(driver)\n",
    "    save_countries_file(country_list)\n",
    "\n",
    "    # --- Final Cleanup and Summary ---\n",
    "    driver.quit()\n",
    "    \n",
    "    print(\"--- Scraping Complete ---\")\n",
    "    print(f\"Saved {len(timeline_events)} events to 20th_century_events.txt\")\n",
    "    print(f\"Saved {len(country_list)} countries to country_list.txt\")\n",
    "\n",
    "# This ensures the main function runs only when the script is executed directly.\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fff6fc-18aa-4f54-9430-d04a0627da70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70842d72-c12a-4526-91db-dfcdb73b865f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
